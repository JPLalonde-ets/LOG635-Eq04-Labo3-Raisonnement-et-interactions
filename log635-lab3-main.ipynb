{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <font color=\"red\">1 | SYSTÈME DE</font> RAISONNEMENT\n",
    "---\n",
    "\n",
    "Dans ce notebook, vous apprendrez à implémenter un système de raisonnement avec des connaissances de base sur le monde des meurtres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">1.1 - Les</font> paquets"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T23:18:13.070847Z",
     "start_time": "2025-08-04T23:18:12.887956Z"
    }
   },
   "source": [
    "from aima.logic import *\n",
    "import nltk\n",
    "import speech_recognition as sr\n",
    "from aima3.logic import *"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">1.2 - Le moteur d'</font> inférence"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T23:18:13.096944Z",
     "start_time": "2025-08-04T23:18:13.075003Z"
    }
   },
   "source": [
    "# Permet d'inferer qui est le meurtrier, quand, comment, où il a tué.\n",
    "class CrimeInference:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.weapons = [\"Corde\", \"Fusil\", \"Couteau\", \"Clé_anglaise\", \"Matraque\", \"Poison\"]\n",
    "        self.rooms = [\"Phare\", \"Radio_room\", \"Embarcadère\", \"Plage\", \"Observatoire\", \"Serre\", \"Générateur\"]\n",
    "        self.persons = [\"Governeur_White\", \"Botaniste_Green\", \"Docteur_Brown\", \"Capitaine_Gray\", \"Ingenieur_Blue\", \"Gardien_de_phare_Red\", \"Professeur_Yellow\"]\n",
    "        \n",
    "        # Liste de clauses (faits) qui seront stockées dans la base de connaissance.\n",
    "        self.clauses = []        \n",
    "        \n",
    "        self.base_clauses()\n",
    "        self.initialize_KB()\n",
    "        self.inference_rules()\n",
    "        \n",
    "        # Base de connaissances (First-order logic - FOL)\n",
    "        self.crime_kb = FolKB(self.clauses)\n",
    "\n",
    "    # Déclaration dans la logique du premier ordre\n",
    "    def base_clauses(self):\n",
    "        # Le paramètre est une arme\n",
    "        self.arme_clause = 'Arme({})'\n",
    "        \n",
    "        # Le paramètre est une pièce\n",
    "        self.piece_clause = 'Piece({})'\n",
    "        \n",
    "        # Le paramètre est une persone\n",
    "        self.personne_clause = 'Personne({})'\n",
    "\n",
    "        # paramètre 1 : arme; paramètre 2 : pièce\n",
    "        # p.ex.: Le couteau se trouve dans la cuisine\n",
    "        self.weapon_room_clause = 'Arme_Piece({},{})'\n",
    "\n",
    "        # paramètre 1 : personne; paramètre 2 : pièce; paramètre 3 : heure\n",
    "        # p.ex.: Mustart était dans la cuisine à 11h00\n",
    "        self.person_room_hour_clause = 'Personne_Piece_Heure({}, {}, {})'\n",
    "\n",
    "        # paramètre 1 : personne; paramètre 2 : piece\n",
    "        # p.ex.: Mustard se trouve dans la cuisine\n",
    "        self.person_room_clause = 'Personne_Piece({}, {})'\n",
    "\n",
    "        # paramète 1 : personne\n",
    "        # p. ex.: Mustard est mort\n",
    "        self.dead_clause = 'EstMort({})'\n",
    "        \n",
    "        # paramète 1 : personne\n",
    "        # p. ex.: Mustard est vivant\n",
    "        self.alive_clause = 'EstVivant({})'\n",
    "\n",
    "        # paramètre 1 : personne\n",
    "        # p. ex.: Mustard est la victime\n",
    "        self.victim_clause = 'Victime({})'\n",
    "\n",
    "        # paramètre 1 : personne\n",
    "        # p. ex.: Mustard a des marques au cou\n",
    "        self.body_mark_clause = 'MarqueCou({})'\n",
    "\n",
    "        # paramètre 1 : piece; paramètre 2 : piece\n",
    "        self.room_different_clause = 'PieceDifferente({},{})'\n",
    "\n",
    "        # paramètre 1 : piece; paramètre 2 : piece\n",
    "        self.weapon_different_clause = 'ArmeDifferente({},{})'\n",
    "\n",
    "        # paramètre 1 : heure\n",
    "        self.crime_hour_clause = 'HeureCrime({})'\n",
    "\n",
    "        # paramètre 1 : heure\n",
    "        self.crime_hour_plus_one_clause = 'UneHeureApresCrime({})'\n",
    "\n",
    "    def initialize_KB(self):\n",
    "        # Clause pour differencier les pièces\n",
    "        for i in range(len(self.rooms)):\n",
    "            for j in range(len(self.rooms)):\n",
    "                if i != j:\n",
    "                    # Le bureau est different de la cuisine = PieceDifferente(Bureau, Cuisine)\n",
    "                    self.clauses.append(expr(self.room_different_clause.format(self.rooms[i], self.rooms[j])))\n",
    "\n",
    "        # Clause pour differencier les armes\n",
    "        for i in range(len(self.weapons)):\n",
    "            for j in range(len(self.weapons)):\n",
    "                if i != j:\n",
    "                    # Le couteau est different de la corde = ArmeDifferente(Couteau, Corde)\n",
    "                    self.clauses.append(expr(self.weapon_different_clause.format(self.weapons[i], self.weapons[j])))\n",
    "\n",
    "        # Initialiser KB sur Armes, Pieces, Personnes\n",
    "        for weapon in self.weapons:\n",
    "            # Le couteau est une arme = Arme(Couteau)\n",
    "            self.clauses.append(expr(self.arme_clause.format(weapon)))\n",
    "\n",
    "        for room in self.rooms:\n",
    "            # La cuisine est une pièce = Piece(Cuisine)\n",
    "            self.clauses.append(expr(self.piece_clause.format(room)))\n",
    "\n",
    "        for person in self.persons:\n",
    "            # Mustar est une personne = Personne(Mustard)\n",
    "            self.clauses.append(expr(self.personne_clause.format(person)))\n",
    "    \n",
    "    # Expressions dans la logique du premier ordre permettant de déduire les caractéristiques du meurtre\n",
    "    def inference_rules(self):\n",
    "        # Determine la piece du crime\n",
    "        self.clauses.append(expr('EstMort(x) & Personne_Piece(x, y) ==> PieceCrime(y)'))\n",
    "\n",
    "        # Determiner l'arme du crime\n",
    "        self.clauses.append(expr('PieceCrime(x) & Arme(y) & Piece_Arme(y, x) ==> ArmeCrime(y)'))\n",
    "        self.clauses.append(expr(\"EstMort(x) & MarqueCou(x) ==> ArmeCrime(Corde)\"))\n",
    "        self.clauses.append(expr(\"EstMort(x) & MarqueFusil(x) ==> ArmeCrime(Fusil)\"))\n",
    "        self.clauses.append(expr(\"EstMort(x) & MarqueCouteau(x) ==> ArmeCrime(Couteau)\"))\n",
    "        self.clauses.append(expr(\"EstMort(x) & MarqueCleAnglaise(x) ==> ArmeCrime(Clé_anglaise)\"))\n",
    "        self.clauses.append(expr(\"EstMort(x) & MarqueMatraque(x) ==> ArmeCrime(Matraque)\"))\n",
    "        self.clauses.append(expr(\"EstMort(x) & MarquePoison(x) ==> ArmeCrime(Poison)\"))\n",
    "\n",
    "        # Si la personne est morte alors elle est la victime et ce n'est pas un suicide\n",
    "        self.clauses.append(expr('EstMort(x) ==> Victime(x)'))\n",
    "\n",
    "        # Si la personne est morte alors elle est innocente et ce n'est pas un suicide\n",
    "        self.clauses.append(expr('EstMort(x) ==> Innocent(x)'))\n",
    "\n",
    "        # Si la personne est vivante et était dans une pièce\n",
    "        # qui ne contient pas l'arme du crime, alors elle est innocente\n",
    "        self.clauses.append(expr(\n",
    "            'EstVivant(p) & UneHeureApresCrime(h1) & Personne_Piece_Heure(p,r2,h1) & PieceCrime(r1)'\n",
    "            ' & PieceDifferente(r1,r2) & ArmeCrime(a1) & Arme_Piece(a2,r2) & ArmeDifferente(a1,a2) ==> Innocent(p)'))\n",
    "\n",
    "        # Si la personne se trouvait dans une piece qui contient l'arme\n",
    "        # qui a tué la victime une heure après le meurtre alors elle est suspecte\n",
    "        self.clauses.append(expr(\n",
    "            'EstVivant(p) & UneHeureApresCrime(h1) & Personne_Piece_Heure(p,r2,h1) & PieceCrime(r1)'\n",
    "            ' & PieceDifferente(r1,r2) & ArmeCrime(a) & Arme_Piece(a,r2) ==> Suspect(p)'))\n",
    "\n",
    "    # Ajouter des clauses, c'est-à-dire des faits, à la base de connaissances\n",
    "    def add_clause(self, clause_string):\n",
    "        self.crime_kb.tell(expr(clause_string))\n",
    "\n",
    "    # Demander à la base de connaissances qui est la victime\n",
    "    def get_victim(self):\n",
    "        result = self.crime_kb.ask(expr('Victime(x)'))\n",
    "        if not result:\n",
    "            return False\n",
    "        else:\n",
    "            return result[x]\n",
    "        \n",
    "    # Demander à la base de connaissances la pièce du meurtre\n",
    "    def get_crime_room(self):\n",
    "        result = self.crime_kb.ask(expr('PieceCrime(x)'))\n",
    "        if not result:\n",
    "            return False\n",
    "        else:\n",
    "            return result[x]\n",
    "\n",
    "    # Demander à la base de connaissances l'arme du meurtrier\n",
    "    def get_crime_weapon(self):\n",
    "        result = self.crime_kb.ask(expr('ArmeCrime(x)'))\n",
    "        if not result:\n",
    "            return result\n",
    "        else:\n",
    "            return result[x]\n",
    "\n",
    "    # Demander à la base de connaissances l'heure du meurtre\n",
    "    def get_crime_hour(self):\n",
    "        result = self.crime_kb.ask(expr('HeureCrime(x)'))\n",
    "        if not result:\n",
    "            return result\n",
    "        else:\n",
    "            return result[x]\n",
    "\n",
    "    def get_crime_hour_plus_one(self):\n",
    "        result = self.crime_kb.ask(expr('UneHeureApresCrime(x)'))\n",
    "        if not result:\n",
    "            return result\n",
    "        else:\n",
    "            return result[x]\n",
    "    \n",
    "    # Demander à la base de connaissances le suspect\n",
    "    def get_suspect(self):\n",
    "        result = self.crime_kb.ask(expr('Suspect(x)'))\n",
    "        if not result:\n",
    "            return result\n",
    "        else:\n",
    "            return result[x]\n",
    "\n",
    "    # Demander à la base de connaissances la liste d'innocents\n",
    "    def get_innocent(self):\n",
    "        result = list(fol_bc_ask(self.crime_kb, expr('Innocent(x)')))\n",
    "        res = []\n",
    "\n",
    "        for elt in result:\n",
    "            if not res.__contains__(elt[x]):\n",
    "                res.append(elt[x])\n",
    "        return res"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">1.3 - Les faits et </font> la déduction\n",
    "---\n",
    "Maintenant que nous avons le moteur de déduction, il est temps de commencer à alimenter la base de connaissances avec les faits du monde.\n",
    "\n",
    "Comme nous communiquerons les faits au moteur d’inférence en français, plusieurs grammaires ont été créées pour interpréter les phrases. Celles-ci se trouvent dans le dossier `grammars`.\n",
    "\n",
    "À partir des grammaires, nous pouvons analyser les phrases et puis les transformer en expressions logiques du premier ordre. C'est à cela que servent les fonctions `results_as_string` et `to_fol`. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T23:18:13.104518Z",
     "start_time": "2025-08-04T23:18:13.098591Z"
    }
   },
   "source": [
    "# Cette fonction retourne le format d'une expression logique de premier ordre\n",
    "def results_as_string(results):\n",
    "    res = ''\n",
    "    for result in results:\n",
    "        # synrep = syntactic representation\n",
    "        # semrep = semantic representation\n",
    "        for (synrep, semrep) in result:            \n",
    "            res += str(semrep)\n",
    "    return res"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction `nltk.interpret_sents` donne une représentation de premier ordre d'un fait en fraçais à partir d'une grammaire. La représentation est récupérée et transmise à la fonction `results_as_string` pour la formater sous la forme Exp(x). Enfin, l'expression mise en forme est renvoyée pour l'ajouter à la base de connaissances."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T23:18:13.112293Z",
     "start_time": "2025-08-04T23:18:13.107587Z"
    }
   },
   "source": [
    "# Cette fonction transforme une phrase en fraçais dans une expression logique du premier ordre\n",
    "def to_fol(fact, grammar):\n",
    "    sent = results_as_string(nltk.interpret_sents(fact, grammar))\n",
    "    print(sent)\n",
    "    return sent    "
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous créons maintenant une instance du moteur d'inférence et commençons à ajouter les faits à la base de connaissances. Les faits sont communiqués en français, interprétés par la grammaire appropriée et ajoutés."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T23:18:13.121845Z",
     "start_time": "2025-08-04T23:18:13.113361Z"
    }
   },
   "source": [
    "agent = CrimeInference()"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T23:18:13.238031Z",
     "start_time": "2025-08-04T23:18:13.123895Z"
    }
   },
   "source": [
    "# Faits\n",
    "facts = [['Scarlet est morte'],\n",
    "        ['Mustard est vivant'],\n",
    "        ['Peacock est vivant'],\n",
    "        ['Plum est vivant'],\n",
    "        ['White est vivant']]\n",
    "\n",
    "# Les fait sont ajoutés à la base de connaissances\n",
    "agent.add_clause(to_fol(facts[0], 'grammars/personne_morte.fcfg'))\n",
    "facts.pop(0)\n",
    "\n",
    "for fact in facts:    \n",
    "    agent.add_clause(to_fol(fact, 'grammars/personne_vivant.fcfg'))"
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Grammar does not cover some of the input words: \"'Scarlet'\".",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[24]\u001B[39m\u001B[32m, line 9\u001B[39m\n\u001B[32m      2\u001B[39m facts = [[\u001B[33m'\u001B[39m\u001B[33mScarlet est morte\u001B[39m\u001B[33m'\u001B[39m],\n\u001B[32m      3\u001B[39m         [\u001B[33m'\u001B[39m\u001B[33mMustard est vivant\u001B[39m\u001B[33m'\u001B[39m],\n\u001B[32m      4\u001B[39m         [\u001B[33m'\u001B[39m\u001B[33mPeacock est vivant\u001B[39m\u001B[33m'\u001B[39m],\n\u001B[32m      5\u001B[39m         [\u001B[33m'\u001B[39m\u001B[33mPlum est vivant\u001B[39m\u001B[33m'\u001B[39m],\n\u001B[32m      6\u001B[39m         [\u001B[33m'\u001B[39m\u001B[33mWhite est vivant\u001B[39m\u001B[33m'\u001B[39m]]\n\u001B[32m      8\u001B[39m \u001B[38;5;66;03m# Les fait sont ajoutés à la base de connaissances\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m agent.add_clause(\u001B[43mto_fol\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfacts\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mgrammars/personne_morte.fcfg\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[32m     10\u001B[39m facts.pop(\u001B[32m0\u001B[39m)\n\u001B[32m     12\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m fact \u001B[38;5;129;01min\u001B[39;00m facts:    \n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[22]\u001B[39m\u001B[32m, line 3\u001B[39m, in \u001B[36mto_fol\u001B[39m\u001B[34m(fact, grammar)\u001B[39m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mto_fol\u001B[39m(fact, grammar):\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m     sent = results_as_string(\u001B[43mnltk\u001B[49m\u001B[43m.\u001B[49m\u001B[43minterpret_sents\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfact\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrammar\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m      4\u001B[39m     \u001B[38;5;28mprint\u001B[39m(sent)\n\u001B[32m      5\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m sent\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\LOG635-Eq04-Labo3-Raisonnement-et-interactions\\.venv\\Lib\\site-packages\\nltk\\sem\\util.py:87\u001B[39m, in \u001B[36minterpret_sents\u001B[39m\u001B[34m(inputs, grammar, semkey, trace)\u001B[39m\n\u001B[32m     73\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34minterpret_sents\u001B[39m(inputs, grammar, semkey=\u001B[33m\"\u001B[39m\u001B[33mSEM\u001B[39m\u001B[33m\"\u001B[39m, trace=\u001B[32m0\u001B[39m):\n\u001B[32m     74\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m     75\u001B[39m \u001B[33;03m    Add the semantic representation to each syntactic parse tree\u001B[39;00m\n\u001B[32m     76\u001B[39m \u001B[33;03m    of each input sentence.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     83\u001B[39m \u001B[33;03m    :rtype: list(list(tuple(nltk.tree.Tree, nltk.sem.logic.ConstantExpression)))\u001B[39;00m\n\u001B[32m     84\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m     85\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[32m     86\u001B[39m         [(syn, root_semrep(syn, semkey)) \u001B[38;5;28;01mfor\u001B[39;00m syn \u001B[38;5;129;01min\u001B[39;00m syntrees]\n\u001B[32m---> \u001B[39m\u001B[32m87\u001B[39m         \u001B[38;5;28;01mfor\u001B[39;00m syntrees \u001B[38;5;129;01min\u001B[39;00m \u001B[43mparse_sents\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrammar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrace\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrace\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     88\u001B[39m     ]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\LOG635-Eq04-Labo3-Raisonnement-et-interactions\\.venv\\Lib\\site-packages\\nltk\\sem\\util.py:47\u001B[39m, in \u001B[36mparse_sents\u001B[39m\u001B[34m(inputs, grammar, trace)\u001B[39m\n\u001B[32m     45\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m sent \u001B[38;5;129;01min\u001B[39;00m inputs:\n\u001B[32m     46\u001B[39m     tokens = sent.split()  \u001B[38;5;66;03m# use a tokenizer?\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m47\u001B[39m     syntrees = \u001B[38;5;28mlist\u001B[39m(\u001B[43mcp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mparse\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtokens\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m     48\u001B[39m     parses.append(syntrees)\n\u001B[32m     49\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m parses\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\LOG635-Eq04-Labo3-Raisonnement-et-interactions\\.venv\\Lib\\site-packages\\nltk\\parse\\chart.py:1474\u001B[39m, in \u001B[36mChartParser.parse\u001B[39m\u001B[34m(self, tokens, tree_class)\u001B[39m\n\u001B[32m   1473\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mparse\u001B[39m(\u001B[38;5;28mself\u001B[39m, tokens, tree_class=Tree):\n\u001B[32m-> \u001B[39m\u001B[32m1474\u001B[39m     chart = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mchart_parse\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtokens\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1475\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28miter\u001B[39m(chart.parses(\u001B[38;5;28mself\u001B[39m._grammar.start(), tree_class=tree_class))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\LOG635-Eq04-Labo3-Raisonnement-et-interactions\\.venv\\Lib\\site-packages\\nltk\\parse\\chart.py:1432\u001B[39m, in \u001B[36mChartParser.chart_parse\u001B[39m\u001B[34m(self, tokens, trace)\u001B[39m\n\u001B[32m   1429\u001B[39m trace_new_edges = \u001B[38;5;28mself\u001B[39m._trace_new_edges\n\u001B[32m   1431\u001B[39m tokens = \u001B[38;5;28mlist\u001B[39m(tokens)\n\u001B[32m-> \u001B[39m\u001B[32m1432\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_grammar\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcheck_coverage\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtokens\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1433\u001B[39m chart = \u001B[38;5;28mself\u001B[39m._chart_class(tokens)\n\u001B[32m   1434\u001B[39m grammar = \u001B[38;5;28mself\u001B[39m._grammar\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\LOG635-Eq04-Labo3-Raisonnement-et-interactions\\.venv\\Lib\\site-packages\\nltk\\grammar.py:666\u001B[39m, in \u001B[36mCFG.check_coverage\u001B[39m\u001B[34m(self, tokens)\u001B[39m\n\u001B[32m    664\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m missing:\n\u001B[32m    665\u001B[39m     missing = \u001B[33m\"\u001B[39m\u001B[33m, \u001B[39m\u001B[33m\"\u001B[39m.join(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mw\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[33m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m w \u001B[38;5;129;01min\u001B[39;00m missing)\n\u001B[32m--> \u001B[39m\u001B[32m666\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    667\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mGrammar does not cover some of the \u001B[39m\u001B[33m\"\u001B[39m \u001B[33m\"\u001B[39m\u001B[33minput words: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m % missing\n\u001B[32m    668\u001B[39m     )\n",
      "\u001B[31mValueError\u001B[39m: Grammar does not cover some of the input words: \"'Scarlet'\"."
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# On se rend compte que Scarlet est morte par étranglement\n",
    "fact = ['Scarlet a des marques au cou']\n",
    "agent.add_clause(to_fol(fact, 'grammars/personne_marque.fcfg'))\n",
    "\n",
    "fact = ['Scarlet est dans le bureau']\n",
    "agent.add_clause(to_fol(fact, 'grammars/personne_piece.fcfg'))\n",
    "\n",
    "# On sait que Peacock est dans le bureau\n",
    "fact = ['Peacock est dans le bureau']\n",
    "agent.add_clause(to_fol(fact, 'grammars/personne_piece.fcfg'))\n",
    "\n",
    "# Demande à Peacock l'heure du decès -> Rep : 14h\n",
    "fact = ['Scarlet est morte à 14h']\n",
    "agent.add_clause(to_fol(fact, 'grammars/personne_morte_heure.fcfg'))\n",
    "\n",
    "uneHeureApres = agent.get_crime_hour() + 1\n",
    "\n",
    "agent.add_clause('UneHeureApresCrime({})'.format(uneHeureApres))\n",
    "\n",
    "# Demande à Peacock dans quelle pièce il était une heure après le meurtre -> Rep : Peacock dans le Salon à 15h\n",
    "fact = ['Peacock était dans le salon à ' + str(uneHeureApres) + 'h']\n",
    "agent.add_clause(to_fol(fact, 'grammars/personne_piece_heure.fcfg'))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Dans le salon\n",
    "\n",
    "# Voit qu'il y a un fusil et Plum dans le salon\n",
    "fact = ['Le fusil est dans le salon']\n",
    "agent.add_clause(to_fol(fact, 'grammars/arme_piece.fcfg'))\n",
    "\n",
    "fact = ['Plum est dans le salon']\n",
    "agent.add_clause(to_fol(fact, 'grammars/personne_piece.fcfg'))\n",
    "\n",
    "# Demande à Plum dans quelle pièce il était une heure après le meurtre -> Rep : Plum dans le Salon à 15h\n",
    "fact = ['Plum était dans le salon à ' + str(uneHeureApres) + 'h']\n",
    "agent.add_clause(to_fol(fact, 'grammars/personne_piece_heure.fcfg'))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Dans la cuisine\n",
    "\n",
    "# Voit qu'il y a un couteau, White et Mustard dans la cuisine\n",
    "fact = ['Le couteau est dans la cuisine']\n",
    "agent.add_clause(to_fol(fact, 'grammars/arme_piece.fcfg'))\n",
    "\n",
    "fact = ['White est dans la cuisine']\n",
    "agent.add_clause(to_fol(fact, 'grammars/personne_piece.fcfg'))\n",
    "\n",
    "fact = ['Mustard est dans la cuisine']\n",
    "agent.add_clause(to_fol(fact, 'grammars/personne_piece.fcfg'))\n",
    "\n",
    "# Demande à White dans quelle pièce il était une heure après le meurtre -> Rep : White dans la Cuisine à 15h\n",
    "fact = ['White était dans la cuisine à ' + str(uneHeureApres) + 'h']\n",
    "agent.add_clause(to_fol(fact, 'grammars/personne_piece_heure.fcfg'))\n",
    "\n",
    "# Demande à Mustard dans quelle pièce il était une heure après le meurtre -> Rep : Mustard dans le Garage à 15h\n",
    "fact = ['Mustard était dans le garage à ' + str(uneHeureApres) + 'h']\n",
    "agent.add_clause(to_fol(fact, 'grammars/personne_piece_heure.fcfg'))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Dans le garage\n",
    "\n",
    "# On se rend compte qu'il y a une corde dans le garage\n",
    "fact = ['La corde est dans le garage']\n",
    "agent.add_clause(to_fol(fact, 'grammars/arme_piece.fcfg'))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, après avoir fourni tous les faits (scénario), nous demandons au moteur d’inférence de tirer ses conclusions."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "print(\"Pièce du crime : \", agent.get_crime_room())\n",
    "print(\"Arme du crime : \", agent.get_crime_weapon())\n",
    "print(\"Personne victime : \", agent.get_victim())\n",
    "print(\"Heure du crime : \", agent.get_crime_hour())\n",
    "print(\"Meurtrier : \", agent.get_suspect())\n",
    "print(\"Personnes innocentes : \", agent.get_innocent())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconnaissance vocale\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T23:20:46.998277Z",
     "start_time": "2025-08-04T23:20:40.395747Z"
    }
   },
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "def reconnaitre_parole():\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Parlez maintenant...\")\n",
    "        r.adjust_for_ambient_noise(source)  # réduit le bruit ambiant\n",
    "        audio = r.listen(source)\n",
    "\n",
    "    try:\n",
    "        texte = r.recognize_google(audio, language=\"fr-FR\")\n",
    "        print(\"Vous avez dit : \" + texte)\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Je n'ai pas compris.\")\n",
    "    except sr.RequestError as e:\n",
    "        print(\"Erreur avec le service Google : {0}\".format(e))\n",
    "\n",
    "# Test\n",
    "# reconnaitre_parole()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎤 Parlez maintenant...\n",
      "✅ Vous avez dit : ceci est un test mon nom est Annie\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
